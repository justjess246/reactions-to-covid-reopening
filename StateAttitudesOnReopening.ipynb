{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for natural language processing, which is used for the tweets\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# allows access to tweets with Python\n",
    "import tweepy as tw\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Cursor\n",
    "\n",
    "import json\n",
    "\n",
    "import re, string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = ''        \n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# dictionary of states and their longitudes and latitudes\n",
    "states = {\n",
    "            \"Alabama\" : \"32.8066,-86.7911\",\n",
    "            \"Alaska\" : \"61.3707,-152.4044\",\n",
    "            \"Arizona\" : \"33.7297,-111.4312\",\n",
    "            \"Arkansas\" : \"34.9697,-92.3731\",\n",
    "            \"California\" : \"36.1162,-119.6815\",\n",
    "            \"Colorado\" : \"39.0598,-105.3111\",\n",
    "            \"Connecticut\" : \"41.5977,-72.7553\",\n",
    "            \"Delaware\" : \"39.3185,-75.5071\",\n",
    "            \"District of Columbia\" : \"38.8974,-77.0268\",\n",
    "            \"Florida\" : \"27.7664,-81.6867\",\n",
    "            \"Georgia\" : \"33.0406,-83.6430\",\n",
    "            \"Hawaii\" : \"21.094318,-157.498337\",\n",
    "            \"Idaho\" : \"44.2404,-114.4788\",\n",
    "            \"Illinois\" : \"40.3494,-88.9861\",\n",
    "            \"Indiana\" : \"39.8494,-86.2582\",\n",
    "            \"Iowa\" : \"42.0115,-93.2105\",\n",
    "            \"Kansas\" : \"38.5266,-96.7264\",\n",
    "            \"Kentucky\" : \"37.6681,-84.6700\",\n",
    "            \"Louisiana\" : \"31.1695,-91.8678\",\n",
    "            \"Maine\" : \"44.6939,-69.3819\",\n",
    "            \"Maryland\" : \"39.0639,-76.8021\",\n",
    "            \"Massachusetts\" : \"42.2301,-71.5301\",\n",
    "            \"Michigan\" : \"43.3266,-84.5360\",\n",
    "            \"Minnesota\" : \"45.6944,-93.9001\",\n",
    "            \"Mississippi\" : \"32.7416,-89.6786\",\n",
    "            \"Missouri\" : \"38.4560,-92.2883\",\n",
    "            \"Montana\" : \"46.9219,-110.4543\",\n",
    "            \"Nebraska\" : \"41.1253,-98.2680\",\n",
    "            \"Nevada\" : \"38.3135,-117.0553\",\n",
    "            \"New Hampshire\" : \"43.4524,-71.5638\",\n",
    "            \"New Jersey\" : \"40.2989,-74.5210\",\n",
    "            \"New Mexico\" : \"34.8405,-106.2484\",\n",
    "            \"New York\" : \"42.1657,-74.9480\",\n",
    "            \"North Carolina\" : \"35.6300,-79.8064\",\n",
    "            \"North Dakota\" : \"47.5289,-99.7840\",\n",
    "            \"Ohio\" : \"40.3887,-82.7649\",\n",
    "            \"Oklahoma\" : \"35.5653,-96.9289\",\n",
    "            \"Oregon\" : \"44.5720,-122.0709\",\n",
    "            \"Pennsylvania\" : \"40.5907,-77.2097\",\n",
    "            \"Rhode Island\" : \"41.6808,-71.5117\",\n",
    "            \"South Carolina\" : \"33.8568,-80.9450\",\n",
    "            \"South Dakota\" : \"44.2997,-99.4388\",\n",
    "            \"Tennessee\" : \"35.7478,-86.6923\",\n",
    "            \"Texas\" : \"31.0544,-97.5634\",\n",
    "            \"Utah\" : \"40.1500,-111.8624\",\n",
    "            \"Vermont\" : \"44.0458,-72.7106\",\n",
    "            \"Virginia\" : \"37.7693,-78.1699\",\n",
    "            \"Washington\" : \"47.4009,-121.4904\",\n",
    "            \"West Virginia\" : \"38.4912,-80.9544\",\n",
    "            \"Wisconsin\" : \"44.2684,-89.6165\",\n",
    "            \"Wyoming\" : \"42.7559,-107.3024\"\n",
    "}\n",
    "        \n",
    "# removes extra symbols from tweets and reduces each word to its dictionary form\n",
    "def remove_noise(tweet_tokens, stop_words = ()):\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                           '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens\n",
    "    \n",
    "# returns element that appears the most in given list\n",
    "# if multiple elements appear the same amount of times, first\n",
    "#     element is returned\n",
    "def mode(array):\n",
    "    most = max(list(map(array.count, array)))\n",
    "    return list(set(filter(lambda x: array.count(x) == most, array)))[0]\n",
    "\n",
    "# analyzes tweets from given state about reopening during covid-19 \n",
    "# returns whether the given state is against, neutral, or lenient \n",
    "#     regarding reopening\n",
    "def state_attitude(state):\n",
    "    search_term = \"#covid+reopening -filter:retweets\"\n",
    "    classifier = pickle.load(open('tweets_text.sav', 'rb'))\n",
    "    attitude = {}\n",
    "\n",
    "    tweets = tw.Cursor(api.search,\n",
    "                        q=search_term,\n",
    "                        geocode=states[state] + \",200km\",\n",
    "                        lang=\"en\",\n",
    "                        since='2020-06-01').items(100)\n",
    "\n",
    "    all_tweets = [tweet.text for tweet in tweets]\n",
    "    \n",
    "    if len(all_tweets) > 0:\n",
    "\n",
    "        tweet_tokenizer = TweetTokenizer()\n",
    "        ans = []\n",
    "\n",
    "        for custom_tweet in all_tweets:\n",
    "            custom_tokens = remove_noise(tweet_tokenizer.tokenize(custom_tweet))\n",
    "            ans.append(classifier.classify(dict([token, True] for token in custom_tokens)))\n",
    "\n",
    "        attitude[state] = mode(ans)\n",
    "    else:\n",
    "        attitude[state] = \"Neutral on reopening\"  \n",
    "    return attitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alabama': 'Lenient on reopening'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "state_attitude(\"Alabama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
